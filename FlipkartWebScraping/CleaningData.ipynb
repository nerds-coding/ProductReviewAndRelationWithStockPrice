{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zx-iI-Slr53b"
   },
   "outputs": [],
   "source": [
    "#pip install vaderSentiment\n",
    "#pip install emoji\n",
    "\n",
    "#pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "8AdSF8k7KpTC",
    "outputId": "0d0637a9-0110-47af-eec8-b1ea8ab8c903"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import re\n",
    "\n",
    "import emoji\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "id": "c8KNsumAEtp9",
    "outputId": "23c6057b-4600-4181-86a8-9f554072fce6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/anupprakash/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anupprakash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/anupprakash/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anupprakash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anupprakash/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "spell = Speller(lang='en')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0I6ENuWMt7qr"
   },
   "outputs": [],
   "source": [
    "slangs = {}\n",
    "slangs_df = pd.read_csv('/Users/anupprakash/Desktop/Review And Stock Price/FlipkartReviews/AllSlangs.csv')\n",
    "slangs_df.drop('Unnamed: 0',1,inplace=True)\n",
    "slangs_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ocvg5V-kuj7a"
   },
   "outputs": [],
   "source": [
    "for index,rows in slangs_df.iterrows():slangs[str(rows['Abbreviation'].replace(' ',''))] = str(rows['FullForm'].lower()).strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qddSfafWUa4c"
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "\"n't\":'not' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrdvVA7iOyy0"
   },
   "outputs": [],
   "source": [
    "# Reading Excel Sheet from folder\n",
    "#/content/drive/My Drive/ColabDataset/SentimentAndStockStudy/TawaReview.xlsx\n",
    "BottomPressureCooker = pd.read_excel(\"/Users/anupprakash/Desktop/Review And Stock Price/FlipkartReviews/BottomPressureCooker.xlsx\",\"AllReview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "J6aSfRBffnPz",
    "outputId": "374d321f-7045-4749-83f9-5e7398376b65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Rating</th>\n",
       "      <th>User Review</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Review Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have quite impressed with the amazing qualit...</td>\n",
       "      <td>Sushant Chaulkar</td>\n",
       "      <td>Jun, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Sure Delivery from Flipkart not 5 ðŸŒŸ  I will gi...</td>\n",
       "      <td>Patrick Michael</td>\n",
       "      <td>5months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>this price is very best for this product and a...</td>\n",
       "      <td>chetan singh</td>\n",
       "      <td>7months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>it's very nice product so I'm happy and excite...</td>\n",
       "      <td>Lokanath Patra</td>\n",
       "      <td>Jan, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice product. Worth of writing a review. Excel...</td>\n",
       "      <td>Sultan Mustafijul Hoque</td>\n",
       "      <td>Nov, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>super good work I like that's</td>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>10months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>i bought this to my wife.. she felt very happy...</td>\n",
       "      <td>Nagaraj  Govindaraj</td>\n",
       "      <td>7months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>good product worth for money pack is also good...</td>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>8months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>very nice super product but no ISI mark improv...</td>\n",
       "      <td>Ganesh Rk</td>\n",
       "      <td>8months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User Rating                                        User Review  \\\n",
       "0          NaN                                                NaN   \n",
       "1          5.0  I have quite impressed with the amazing qualit...   \n",
       "2          5.0  Sure Delivery from Flipkart not 5 ðŸŒŸ  I will gi...   \n",
       "3          4.0  this price is very best for this product and a...   \n",
       "4          4.0  it's very nice product so I'm happy and excite...   \n",
       "5          5.0  Nice product. Worth of writing a review. Excel...   \n",
       "6          5.0                      super good work I like that's   \n",
       "7          4.0  i bought this to my wife.. she felt very happy...   \n",
       "8          5.0  good product worth for money pack is also good...   \n",
       "9          4.0  very nice super product but no ISI mark improv...   \n",
       "\n",
       "                 User Name   Review Date  \n",
       "0                      NaN           NaN  \n",
       "1         Sushant Chaulkar     Jun, 2019  \n",
       "2          Patrick Michael   5months ago  \n",
       "3             chetan singh   7months ago  \n",
       "4           Lokanath Patra     Jan, 2019  \n",
       "5  Sultan Mustafijul Hoque     Nov, 2018  \n",
       "6        Flipkart Customer  10months ago  \n",
       "7      Nagaraj  Govindaraj   7months ago  \n",
       "8        Flipkart Customer   8months ago  \n",
       "9                Ganesh Rk   8months ago  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BottomPressureCooker.head(10)#MixtureGrinderReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "colab_type": "code",
    "id": "bKxB-gKTudC8",
    "outputId": "e27147b6-fa69-4089-e0d0-d62ef4efbaa5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Rating</th>\n",
       "      <th>User Review</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>DateOfReview</th>\n",
       "      <th>FinalText</th>\n",
       "      <th>FinalTextSentimentNegative</th>\n",
       "      <th>FinalTextSentimentPositive</th>\n",
       "      <th>FinalTextSentimentNeutral</th>\n",
       "      <th>FinalTextSentimentCompound</th>\n",
       "      <th>FinalTextSentiment</th>\n",
       "      <th>UserReviewSentimentNegative</th>\n",
       "      <th>UserReviewSentimentPositive</th>\n",
       "      <th>UserReviewSentimentNeutral</th>\n",
       "      <th>UserReviewSentimentCompound</th>\n",
       "      <th>UserReviewSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have quite impressed with the amazing qualit...</td>\n",
       "      <td>Sushant Chaulkar</td>\n",
       "      <td>Jun, 2019</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>I quite impress amazing quality pressure cooke...</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Youre Delivery from Flipkart not 5   I will gi...</td>\n",
       "      <td>Patrick Michael</td>\n",
       "      <td>5months ago</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>Youre Delivery Flipkart 5 I give 100 Butter fl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>this price is very best for this product and a...</td>\n",
       "      <td>chetan singh</td>\n",
       "      <td>7months ago</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>price best product valuable company trust good</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>it is very nice product so I am happy and exci...</td>\n",
       "      <td>Lokanath Patra</td>\n",
       "      <td>Jan, 2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>nice product I happy excite price thank Flipkart</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice product. Worth of writing a review. Excel...</td>\n",
       "      <td>Sultan Mustafijul Hoque</td>\n",
       "      <td>Nov, 2018</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>Nice product Worth write review Excellent deli...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Muhammed Farhan Mammu</td>\n",
       "      <td>1month ago</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Vanishree Yeshwanth</td>\n",
       "      <td>1month ago</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>salauddin Biswas</td>\n",
       "      <td>1month ago</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>5.0</td>\n",
       "      <td>very Best product  this is good product thanks...</td>\n",
       "      <td>S K  Tiwari</td>\n",
       "      <td>1month ago</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>Best product good product thanks Flipkart product</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Very good  product</td>\n",
       "      <td>Bhawana Kumari</td>\n",
       "      <td>1month ago</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>Very good product</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User Rating                                        User Review  \\\n",
       "1             5.0  I have quite impressed with the amazing qualit...   \n",
       "2             5.0  Youre Delivery from Flipkart not 5   I will gi...   \n",
       "3             4.0  this price is very best for this product and a...   \n",
       "4             4.0  it is very nice product so I am happy and exci...   \n",
       "5             5.0  Nice product. Worth of writing a review. Excel...   \n",
       "...           ...                                                ...   \n",
       "1037          4.0                                               Good   \n",
       "1038          4.0                                          Excellent   \n",
       "1039          5.0                                          Excellent   \n",
       "1040          5.0  very Best product  this is good product thanks...   \n",
       "1041          4.0                                 Very good  product   \n",
       "\n",
       "                    User Name  Review Date DateOfReview  \\\n",
       "1            Sushant Chaulkar    Jun, 2019   2019-06-03   \n",
       "2             Patrick Michael  5months ago   2020-03-03   \n",
       "3                chetan singh  7months ago   2020-01-03   \n",
       "4              Lokanath Patra    Jan, 2019   2019-01-03   \n",
       "5     Sultan Mustafijul Hoque    Nov, 2018   2018-11-03   \n",
       "...                       ...          ...          ...   \n",
       "1037    Muhammed Farhan Mammu   1month ago   2020-07-03   \n",
       "1038     Vanishree Yeshwanth    1month ago   2020-07-03   \n",
       "1039         salauddin Biswas   1month ago   2020-07-03   \n",
       "1040              S K  Tiwari   1month ago   2020-07-03   \n",
       "1041           Bhawana Kumari   1month ago   2020-07-03   \n",
       "\n",
       "                                              FinalText  \\\n",
       "1     I quite impress amazing quality pressure cooke...   \n",
       "2     Youre Delivery Flipkart 5 I give 100 Butter fl...   \n",
       "3        price best product valuable company trust good   \n",
       "4      nice product I happy excite price thank Flipkart   \n",
       "5     Nice product Worth write review Excellent deli...   \n",
       "...                                                 ...   \n",
       "1037                                               Good   \n",
       "1038                                          Excellent   \n",
       "1039                                          Excellent   \n",
       "1040  Best product good product thanks Flipkart product   \n",
       "1041                                  Very good product   \n",
       "\n",
       "      FinalTextSentimentNegative  FinalTextSentimentPositive  \\\n",
       "1                          0.121                       0.440   \n",
       "2                          0.000                       0.440   \n",
       "3                          0.000                       0.818   \n",
       "4                          0.000                       0.752   \n",
       "5                          0.000                       0.548   \n",
       "...                          ...                         ...   \n",
       "1037                       0.000                       1.000   \n",
       "1038                       0.000                       1.000   \n",
       "1039                       0.000                       1.000   \n",
       "1040                       0.000                       0.714   \n",
       "1041                       0.000                       0.615   \n",
       "\n",
       "      FinalTextSentimentNeutral  FinalTextSentimentCompound  \\\n",
       "1                         0.439                      0.9236   \n",
       "2                         0.560                      0.8957   \n",
       "3                         0.182                      0.9260   \n",
       "4                         0.248                      0.9022   \n",
       "5                         0.452                      0.8720   \n",
       "...                         ...                         ...   \n",
       "1037                      0.000                      0.4404   \n",
       "1038                      0.000                      0.5719   \n",
       "1039                      0.000                      0.5719   \n",
       "1040                      0.286                      0.8750   \n",
       "1041                      0.385                      0.4927   \n",
       "\n",
       "     FinalTextSentiment  UserReviewSentimentNegative  \\\n",
       "1                   pos                        0.053   \n",
       "2                   pos                        0.000   \n",
       "3                   pos                        0.000   \n",
       "4                   pos                        0.000   \n",
       "5                   pos                        0.000   \n",
       "...                 ...                          ...   \n",
       "1037                pos                        0.000   \n",
       "1038                pos                        0.000   \n",
       "1039                pos                        0.000   \n",
       "1040                pos                        0.000   \n",
       "1041                  0                        0.000   \n",
       "\n",
       "      UserReviewSentimentPositive  UserReviewSentimentNeutral  \\\n",
       "1                           0.276                       0.670   \n",
       "2                           0.289                       0.711   \n",
       "3                           0.520                       0.480   \n",
       "4                           0.479                       0.521   \n",
       "5                           0.456                       0.544   \n",
       "...                           ...                         ...   \n",
       "1037                        1.000                       0.000   \n",
       "1038                        1.000                       0.000   \n",
       "1039                        1.000                       0.000   \n",
       "1040                        0.563                       0.437   \n",
       "1041                        0.615                       0.385   \n",
       "\n",
       "      UserReviewSentimentCompound UserReviewSentiment  \n",
       "1                          0.9430                 pos  \n",
       "2                          0.8957                 pos  \n",
       "3                          0.9335                 pos  \n",
       "4                          0.8991                 pos  \n",
       "5                          0.8720                 pos  \n",
       "...                           ...                 ...  \n",
       "1037                       0.4404                 pos  \n",
       "1038                       0.5719                 pos  \n",
       "1039                       0.5719                 pos  \n",
       "1040                       0.8832                 pos  \n",
       "1041                       0.4927                   0  \n",
       "\n",
       "[1041 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PreprocessingData:\n",
    "\n",
    "  def __init__(self,df,df_name='',location=''):\n",
    "    self.df = df\n",
    "    self.df.dropna(inplace=True)\n",
    "    self.df_name = df_name\n",
    "    self.location = location\n",
    "\n",
    "\n",
    "  # ----------------------------- Change Raw date to Pandas Date Time foramt -----------------------------------------\n",
    "  def ago_do_date(self,ago):\n",
    "    j = re.search(r'(\\d+)(\\w+) ago',ago)\n",
    "    if(j):\n",
    "      value = j.group(1)\n",
    "      unit = j.group(2)\n",
    "      if(not unit.endswith(\"s\")):\n",
    "        unit+='s'\n",
    "      delta = relativedelta(**{unit: int(value)})\n",
    "      date = datetime.now() - delta\n",
    "      return date.date()\n",
    "    elif(ago=='Today'):\n",
    "      return datetime.now().date()\n",
    "    elif(ago!='Today'):\n",
    "      dt = parse(ago.replace(\",\",''))\n",
    "      return dt.date()\n",
    "\n",
    "  \n",
    "\n",
    "  # ----------------------------- Removing Emojis From Raw Text -----------------------------------------\n",
    "  def removingEmojis(self,reviews):\n",
    "    return ''.join(rev for rev in reviews if rev not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "\n",
    "\n",
    "  # ----------------------------- Removing Slangs from Raw Text -----------------------------------------\n",
    "  def removingSlangs(self,reviews):\n",
    "    doc = regexp_tokenize(reviews, \"[\\w']+\") \n",
    "\n",
    "    for token in doc:\n",
    "      if(token in CONTRACTION_MAP):\n",
    "        reviews = reviews.replace(token,CONTRACTION_MAP[token])\n",
    "      elif(token in slangs):\n",
    "        reviews = reviews.replace(token,slangs[token])\n",
    "    return reviews\n",
    "\n",
    "  \n",
    "  \n",
    "  # ----------------------------- Checking Non-English Words and Replacing Miss-Pronounce Word With Actuall Words  -----------------------------------------\n",
    "  def checkingNonEnglishWords(self,reviews):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    for w in regexp_tokenize(reviews, \"[\\w']+\"):\n",
    "      if ((w.lower() not in words) and (w.lower()!= 'flipkart')):\n",
    "        reviews = reviews.replace(w,spell(w))\n",
    "    return reviews\n",
    "\n",
    "\n",
    "  \n",
    "  # ----------------------------- Part of Speech Tagging -----------------------------------------\n",
    "  def get_wordnet_pos(self,pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "        \n",
    "  \n",
    "  # ----------------------------- Removing StopWords and Lemmatizing Words -----------------------------------------\n",
    "  def CleaningData(self,val):\n",
    "    rex = re.sub(r'[^a-zA-Z0-9]+',' ',val)\n",
    "\n",
    "    pos = pos_tag(word_tokenize(rex))\n",
    "\n",
    "    filter = [WordNetLemmatizer().lemmatize(x[0],PreprocessingData.get_wordnet_pos(self,x[1])) for x in pos if x[0] not in stopwords.words('english')]\n",
    "\n",
    "    filter = ' '.join(filter)\n",
    "\n",
    "    return filter\n",
    "\n",
    "    \n",
    "  \n",
    "  # ----------------------------- Getting the Polarity of Text(both Clean and Raw) -----------------------------------------\n",
    "  def sentiment_analyzer_scores(self,sentence):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    if(score['compound']>=0.2):\n",
    "        return [score['neg'],score['pos'],score['neu'],score['compound'],str('pos')]\n",
    "    elif(score['compound']<=-0.2):\n",
    "        return [score['neg'],score['pos'],score['neu'],score['compound'],str('neg')]\n",
    "    else:\n",
    "        return [score['neg'],score['pos'],score['neu'],score['compound'],str('neu')]\n",
    "  \n",
    "\n",
    "  def processRawData(self):\n",
    "    #Date\n",
    "    self.df['DateOfReview'] = self.df['Review Date'].apply(lambda x :PreprocessingData.ago_do_date(self,x))\n",
    "\n",
    "    \n",
    "    #Emojis\n",
    "    self.df['User Review'] = self.df['User Review'].apply(lambda x :PreprocessingData.removingEmojis(self,x))\n",
    "\n",
    "    #Removing Slangs\n",
    "    self.df['User Review'] = self.df['User Review'].apply(lambda x :PreprocessingData.removingSlangs(self,x))\n",
    "\n",
    "    #checkingNonEnglishWords\n",
    "    self.df['User Review'] = self.df['User Review'].apply(lambda x :PreprocessingData.checkingNonEnglishWords(self,x))\n",
    "\n",
    "    #CleaningData\n",
    "    self.df['FinalText'] = self.df['User Review'].apply(lambda x :PreprocessingData.CleaningData(self,x))\n",
    "    \n",
    "\n",
    "    #sentiment_analyzer_scores\n",
    "    (self.df['FinalTextSentimentNegative'], self.df['FinalTextSentimentPositive'], self.df['FinalTextSentimentNeutral'], self.df['FinalTextSentimentCompound'], self.df['FinalTextSentiment'])  = 0,0,0,0,0\n",
    "    (self.df['UserReviewSentimentNegative'],self.df['UserReviewSentimentPositive'],self.df['UserReviewSentimentNeutral'],self.df['UserReviewSentimentCompound'],self.df['UserReviewSentiment']) =0,0,0,0,0\n",
    "    m = self.df['FinalText'].apply(lambda x :PreprocessingData.sentiment_analyzer_scores(self,x))    \n",
    "    j = self.df['User Review'].apply(lambda x :PreprocessingData.sentiment_analyzer_scores(self,x))\n",
    "    for x in range(len(m)):\n",
    "        self.df['FinalTextSentimentNegative'].iloc[x] = m.iloc[x][0]\n",
    "        self.df['FinalTextSentimentPositive'].iloc[x]= m.iloc[x][1]\n",
    "        self.df['FinalTextSentimentNeutral'].iloc[x]= m.iloc[x][2]\n",
    "        self.df['FinalTextSentimentCompound'].iloc[x] = m.iloc[x][3] \n",
    "        self.df['FinalTextSentiment'].loc[x] = m.iloc[x][4]\n",
    "\n",
    "    for x in range(len(j)):\n",
    "        self.df['UserReviewSentimentNegative'].iloc[x] = j.iloc[x][0]\n",
    "        self.df['UserReviewSentimentPositive'].iloc[x]= j.iloc[x][1]\n",
    "        self.df['UserReviewSentimentNeutral'].iloc[x]= j.iloc[x][2]\n",
    "        self.df['UserReviewSentimentCompound'].iloc[x] = j.iloc[x][3] \n",
    "        self.df['UserReviewSentiment'].loc[x] = j.iloc[x][4]\n",
    "        #print(type(m))\n",
    "    \n",
    "    self.df.to_csv(str(fileLocation+excelSheetName+'.csv'),index=False)\n",
    "\n",
    "\n",
    "\n",
    "fileLocation = '/Users/anupprakash/Desktop/Review And Stock Price/FlipkartReviews/PreProcessDataset/'\n",
    "excelSheetName = \"BottomPressureCooker\"\n",
    "dataFrame = BottomPressureCooker\n",
    "\n",
    "\n",
    "mj = PreprocessingData(dataFrame ,excelSheetName,fileLocation)\n",
    "mj.processRawData()\n",
    "\n",
    "\n",
    "\n",
    "BottomPressureCooker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CleaningData",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
